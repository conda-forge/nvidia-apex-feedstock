{% set version = "25.04" %}

package:
  name: nvidia-apex
  version: {{ version }}

source:
  url: https://github.com/NVIDIA/apex/archive/refs/tags/{{ version }}.tar.gz
  sha256: 29f02e07327ab65fcff587a4097fb9d24fe73b0a0369c81126672fe36e4bd82e

build:
  number: 0
  # pytorch in conda-forge does not support CUDA 11.8 as of v2.5
  skip: true  # [win or cuda_compiler_version in ("None", "11.8")]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
  script_env:
    - TORCH_CUDA_ARCH_LIST=5.0;6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0+PTX  # [(cuda_compiler_version or "").startswith("12")]
  script:
    - python -m pip install . -vv

requirements:
  build:
    - {{ stdlib("c") }}
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}
  host:
    - python
    - pip
    - setuptools
    - packaging
    - pytorch
    - pytorch =*=cuda*
  run:
    - python
    - cxxfilt
    - tqdm
    - numpy
    - pyyaml
    - pytest
    - packaging
  run_constrained:
    - pytorch =*=cuda*

test:
  imports:
    - apex
    - apex.amp
    - apex.parallel
    - apex.optimizers
    - apex.normalization.fused_layer_norm

about:
  home: "https://nvidia.github.io/apex/"
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
  doc_url: "https://nvidia.github.io/apex/"
  dev_url: "https://github.com/NVIDIA/apex"

extra:
  recipe-maintainers:
    - h-vetinari
    - oblute
    - benhuff
    - jakirkham
    - rluria14
