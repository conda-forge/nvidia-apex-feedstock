{% set version = "23.08" %}
{% set proc_version = "1.0.0" %}

# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
{% set proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

package:
  name: nvidia-apex-split
  version: {{ version }}

source:
  url: https://github.com/NVIDIA/apex/archive/refs/tags/{{ version }}.tar.gz
  sha256: a6ab2d10b681b621a96c028d6727d133fdaea6dd4c30f0546f70cf6904de522e

build:
  number: 0
  skip: true  # [osx or win]

outputs:
  - name: nvidia-apex-proc
    version: {{ proc_version }}
    build:
      string: {{ proc_type }}
    test:
      commands:
        - exit 0
    about:
      home: https://github.com/conda-forge/nvidia-apex-feedstock
      license: BSD-3-Clause
      license_family: BSD
      summary: A meta-package to select CPU or GPU nvidia-apex build.

  - name: nvidia-apex
    version: {{ version }}
    build:
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == "None"]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      script:
        - export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6"
        - python -m pip install . -vv --no-build-isolation
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [linux64 and cuda_compiler_version != "None"]
      host:
        - python
        - pytorch
        - pytorch =*={{ proc_type }}*
        - setuptools
        - packaging
        - pip
        - wheel
      run:
        - python
        - cxxfilt  # [linux]
        - tqdm
        - numpy
        - PyYAML
        - pytest
      run_constrained:
        - nvidia-apex-proc =*=cuda         # [cuda_compiler_version != "None"]
        - nvidia-apex-proc =*=cpu          # [cuda_compiler_version == "None"]
        - pytorch =*={{ proc_type }}*
    test:
      imports:
        - apex
        - apex.amp
        - apex.parallel
        - apex.optimizers
        - apex.normalization.fused_layer_norm
    about:
      home: "https://nvidia.github.io/apex/"
      license: BSD-3-Clause
      license_family: BSD
      license_file: LICENSE
      summary: "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
      doc_url: "https://nvidia.github.io/apex/"
      dev_url: "https://github.com/NVIDIA/apex"

about:
  home: "https://nvidia.github.io/apex/"
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: "a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
  doc_url: "https://nvidia.github.io/apex/"
  dev_url: "https://github.com/NVIDIA/apex"

extra:
  recipe-maintainers:
    - h-vetinari
    - oblute
    - benhuff
    - jakirkham
    - rluria14
  feedstock-name: nvidia-apex
